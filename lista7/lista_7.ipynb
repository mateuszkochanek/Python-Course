{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2\n",
    "\n",
    "Wykorzystując architekturę sieci neuronowych RetinaNet Focal Loss for Dense Object Detection zaprogramuj wykrywanie obiektów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def grab_camera_snapshot(camera_id=0, fallback_filename='zdjecie.jpg'):\n",
    "    camera = cv2.VideoCapture(camera_id)\n",
    "    try:\n",
    "        for i in range(15):\n",
    "            snapshot_ok, image = camera.read()\n",
    "        if not snapshot_ok:\n",
    "            print(\"Ups: could not access camera\")\n",
    "            if fallback_filename:\n",
    "                image = read_image_bgr(fallback_filename)\n",
    "    finally:\n",
    "        camera.release()\n",
    "    return image\n",
    "\n",
    "gpu = 0\n",
    "setup_gpu(gpu)\n",
    "\n",
    "# wybieramy model\n",
    "model_path = os.path.join('.', '', 'resnet50_coco_best_v2.1.0.h5')\n",
    "model = models.load_model(model_path, backbone_name='resnet50')\n",
    "\n",
    "labels_to_names = {\n",
    "    0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane',\n",
    "    5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light',\n",
    "    10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench',\n",
    "    14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow',\n",
    "    20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack',\n",
    "    25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee',\n",
    "    30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite',\n",
    "    34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard',\n",
    "    37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass',\n",
    "    41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl',\n",
    "    46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli',\n",
    "    51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake',\n",
    "    56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed',\n",
    "    60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse',\n",
    "    65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave',\n",
    "    69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book',\n",
    "    74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear',\n",
    "    78: 'hair drier', 79: 'toothbrush'}\n",
    "\n",
    "# ładujemy obrazek, moze byc algo konkretny albo z kamery\n",
    "#image = read_image_bgr('003.jpg')\n",
    "image = grab_camera_snapshot()\n",
    "\n",
    "# tworzenie kopii obrazka po której będziemy malować i którą wyświetlimy\n",
    "draw = image.copy()\n",
    "draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# przygotowanie obrazka\n",
    "image = preprocess_image(image)\n",
    "image, scale = resize_image(image)\n",
    "\n",
    "# przepuszczenie obrazka przez sieć\n",
    "start = time.time()\n",
    "boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "print(\"processing time: \", time.time() - start)\n",
    "\n",
    "# przeskalowanie naszych pudełek ktore będziemy rysować na obrazku\n",
    "boxes /= scale\n",
    "\n",
    "# jeżeli score byl > 50 to wtedy rysujemy na obrazku\n",
    "for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "    # scores są posortowane więc jak trafimy na mniejszy niż 0.5 to mozemy dalej nie sprawdzać\n",
    "    # chociaż z ciekawości ustawilem na mniejszy\n",
    "    # wiecej rysuje, ale i więcej sie myli, czego się spodziwałem\n",
    "    if score < 0.5:\n",
    "        break\n",
    "    color = label_color(label)\n",
    "    b = box.astype(int)\n",
    "    draw_box(draw, b, color=color)\n",
    "    caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "    draw_caption(draw, b, caption)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(draw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3\n",
    "\n",
    "Zapoznaj się z różnymi modelami dostępnymi w Kerasie https://keras.io/applications/ oraz wykładem 12. Wybierz architekturę MobileNet lub Squeeze-and-Excitation network. Przeczytaj publikację i samodzielnie zaimplementuj ją w Kerasie. Postaraj się uzyskać dobrą wydajność na małych zbiorach danych np. CIFAR-10.\n",
    "\n",
    "Próbowałem zastosować tą sieć do obrazków 32x32, momo że prawdopodobnie lepiej by było gdybym przeskalował obrazki do tych wielkości które są podane w dokumentacji(np 224x224). Próbowałem zastosować to co jest robione w implementacji keras-a czyli usunąć tzw \"top\" (w tym wypadku go zedytować) w jakiś sposób żeby ilość wejść nie zanikała całkowicie. Mimo to widzę, że moja siecie nie uzyskuje dobrej wydajności ale nie zdążyłem tego naprawić przed końcem terminu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def myMobileNet(alpha):\n",
    "    num_classes = 10\n",
    "    inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "    x = Conv(inputs, filters=32, kernel_size=3, strides=2, alpha=alpha)\n",
    "    x = ConvDw(x, filters=32, strides=1, alpha=alpha)\n",
    "    x = Conv(x, filters=64, kernel_size=1, alpha=alpha)\n",
    "    x = ConvDw(x, filters=64, strides=2, alpha=alpha)\n",
    "    x = Conv(x, filters=128, kernel_size=1, alpha=alpha)\n",
    "    x = ConvDw(x, filters=128, strides=1, alpha=alpha)\n",
    "    x = Conv(x, filters=128, kernel_size=1, alpha=alpha)\n",
    "    x = ConvDw(x, filters=128, strides=2, alpha=alpha)\n",
    "    x = Conv(x, filters=256, kernel_size=1, alpha=alpha)\n",
    "    x = ConvDw(x, filters=256, strides=1, alpha=alpha)\n",
    "    x = Conv(x, filters=256, kernel_size=1, alpha=alpha)\n",
    "    x = ConvDw(x, filters=256, strides=2, alpha=alpha)\n",
    "    x = Conv(x, filters=512, kernel_size=1, alpha=alpha)\n",
    "    for i in range( 5 ):\n",
    "        x = ConvDw(x, filters=512 , strides=1 , alpha=alpha)\n",
    "        x = Conv(x, filters=512 , kernel_size=1 , alpha=alpha)\n",
    "    x = ConvDw(x, filters=512, strides=2, alpha=alpha)\n",
    "    x = Conv(x, filters=1024, kernel_size=1, alpha=alpha)\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=(1, 1))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(num_classes)(x)\n",
    "    outputs = tf.keras.layers.Activation('softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def ConvDw( x , filters , strides , alpha=1.0 ):\n",
    "    x = tf.keras.layers.DepthwiseConv2D( kernel_size=3 , padding='same' )( x )\n",
    "    x = tf.keras.layers.BatchNormalization(momentum=0.999)( x )\n",
    "    x = tf.keras.layers.Activation( 'relu' )( x )\n",
    "    x = tf.keras.layers.Conv2D( np.floor( filters * alpha ) , kernel_size=( 1 , 1 ) , strides=strides , use_bias=False , padding='same' )( x )\n",
    "    x = tf.keras.layers.BatchNormalization(momentum=0.999)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def Conv( x , filters , kernel_size , strides=1 , alpha=1.0 ):\n",
    "    x = tf.keras.layers.Conv2D( np.floor( filters * alpha ) , kernel_size=kernel_size , strides=strides , use_bias=False , padding='same' )( x )\n",
    "    x = tf.keras.layers.BatchNormalization( momentum=0.999 )(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = np.array( x_train ) / 255\n",
    "y_train = np.array( y_train )\n",
    "x_test = np.array( x_test ) / 255\n",
    "y_test = np.array( y_test )\n",
    "model = myMobileNet(1.0)\n",
    "model.summary()\n",
    "n_epochs = 15\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.SGD(lr=0.1),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=x_train, y=y_train,\n",
    "    epochs=n_epochs,\n",
    ")\n",
    "model.evaluate(x=x_test, y=y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
